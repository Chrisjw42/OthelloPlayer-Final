{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dbGeneration as db\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned data points in 81 batches\n"
     ]
    }
   ],
   "source": [
    "tensorInputs, raw_labels = db.get_tensorinputs_and_labels()\n",
    "tensorInputs = np.asarray(tensorInputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13539380 training samples\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "\n",
    "for i in tensorInputs:\n",
    "    n += len(i)\n",
    "    \n",
    "print(n, \"training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81]\n",
      "13539380\n",
      "13539380\n",
      "[[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0. -1.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0. -1. -1.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  1. -1.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(tensorInputs.shape))\n",
    "\n",
    "tensorInputs2 = []\n",
    "raw_labels2 = []\n",
    "\n",
    "for i in tensorInputs:\n",
    "    for j in i:\n",
    "        tensorInputs2.append(j)\n",
    "\n",
    "for i in raw_labels:\n",
    "    for j in i:\n",
    "        raw_labels2.append(j)\n",
    "\n",
    "print(len(tensorInputs2))\n",
    "print(len(raw_labels2))\n",
    "\n",
    "print(tensorInputs2[0])\n",
    "print(raw_labels2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_labels = raw_labels2\n",
    "tensorInputs = tensorInputs2\n",
    "del(raw_labels2)\n",
    "del(tensorInputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "print(raw_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_labels = []\n",
    "for i in raw_labels:\n",
    "    if i == -1:\n",
    "        pre_labels.append([1,0])\n",
    "    else:\n",
    "        pre_labels.append([0,1])\n",
    "\n",
    "pre_labels = np.asarray(pre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13539380, 2)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ..., \n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_labels.shape)\n",
    "print(pre_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13539380\n"
     ]
    }
   ],
   "source": [
    "print(len(tensorInputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "N_SAMPLES = len(tensorInputs)\n",
    "N_TRAIN = 12999936\n",
    "N_VALIDATION = int((N_SAMPLES - N_TRAIN)/2)\n",
    "N_BATCHES = int(N_TRAIN/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101562\n"
     ]
    }
   ],
   "source": [
    "print(N_BATCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data to avoid grouping among games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_randomised_batches(training_data, training_labels):\n",
    "    pairs = []\n",
    "    for i in range(len(training_data)):\n",
    "        pairs.append([training_data[i], training_labels[i]])\n",
    "        \n",
    "    random.shuffle(pairs)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in pairs:\n",
    "        x.append(np.reshape(i[0], (100)))\n",
    "        y.append(i[1])\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gameboards = tensorInputs[:N_TRAIN]\n",
    "validation_gameboards = tensorInputs[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_gameboards = tensorInputs[N_TRAIN+N_VALIDATION:]\n",
    "\n",
    "train_labels = pre_labels[:N_TRAIN]\n",
    "validation_labels = pre_labels[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_labels = pre_labels[N_TRAIN+N_VALIDATION:]\n",
    "\n",
    "# Ensure that the validation set fits into batches of size BATCH_SIZE\n",
    "val_batches = int(len(validation_gameboards)/BATCH_SIZE)\n",
    "new_val_length = val_batches*BATCH_SIZE\n",
    "N_VALIDATION = new_val_length\n",
    "validation_gameboards = validation_gameboards[0:N_VALIDATION]\n",
    "validation_labels = validation_labels[0:N_VALIDATION]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(99 % 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12999936\n",
      "269722\n",
      "269696\n",
      "2107\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gameboards))\n",
    "print(len(test_gameboards))\n",
    "print(len(validation_gameboards))\n",
    "print(val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 2. -1. -1. -1. -1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1. -1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1. -1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1.  1.  1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1.  1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1.  1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1.  1. -1. -1. -1. -1.  2.]\n",
      " [ 2. -1. -1. -1. -1. -1. -1. -1. -1.  2.]\n",
      " [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]] [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(test_gameboards[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gameboards = tf.placeholder(tf.float32, (None, 100), name=\"gameBoards\")\n",
    "\n",
    "gameboards2d = tf.reshape(gameboards, (-1, 10, 10, 1), name=\"gameBoards2d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First Convulutional layer, small 2x2 filter\n",
    "conv1 = tf.layers.conv2d(gameboards2d, filters=256, kernel_size=2, padding=\"same\", name=\"Conv1\", activation=tf.nn.relu, strides=1)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, 2, 2, name=\"Pool1\")\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, filters=128, kernel_size=3, padding=\"same\", name=\"Conv2\", activation=tf.nn.relu, strides=1)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, filters=128, kernel_size=4, padding=\"same\", name=\"Conv3\", activation=tf.nn.relu, strides=1)\n",
    "pool3 = tf.layers.max_pooling2d(conv3, 2, 2, name=\"Pool3\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "# Flatten out the pooling - GET THIS NUMBER FROM POOLx.SHAPE\n",
    "pool2_flat = tf.reshape(pool3, (-1, int(1*1*128)), name=\"Pool2_Flat\")\n",
    "\n",
    "# The dropout allows us to train a subset of the neurons at any given iteration.  \n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "\n",
    "# A dense layer with dropout\n",
    "# DENSE - a fully connected linear transofmration of every dimension of the data\n",
    "dense = tf.layers.dense(pool2_flat, int(128), activation=tf.nn.relu, name=\"Dense\")\n",
    "\n",
    "# DROPOUT - if set to 0.5, rendomly select 50% of the neurons to ignore (different with each computation)\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "dense2 = tf.layers.dense(dropout, int(128), activation=tf.nn.relu, name=\"Dense2\")\n",
    "dropout2 = tf.nn.dropout(dense2, keep_prob, name=\"Dropout2\")\n",
    "\n",
    "\n",
    "#dense3 = tf.layers.dense(dropout, int(128), activation=tf.nn.relu, name=\"Dense3\")\n",
    "#dropout3 = tf.nn.dropout(dense2, keep_prob, name=\"Dropout3\")\n",
    "\n",
    "# A dense layer to classify the final values. Only 2 neurons. \n",
    "predictions = tf.layers.dense(dropout2, 2, activation=None, name=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591874\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    #print(shape)\n",
    "    #print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        #print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(128)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None, as in, this is not yet defined, there could be any number of them input. \n",
    "# 2, as in, there are two elements in the one-hot vector\n",
    "\n",
    "labels = tf.placeholder(tf.int32, [None, 2], name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This loss is the elementwise loss\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "\"\"\"with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=predictions))\"\"\"\n",
    "\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\n",
    "\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.001, name=\"Adam\").minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an error rate to evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Error\"):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.cast(tf.not_equal(tf.argmax(labels, 1), tf.argmax(predictions, 1)), tf.float32), name=\"Mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Error\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101562\n"
     ]
    }
   ],
   "source": [
    "number_of_batches = int(N_TRAIN / BATCH_SIZE)\n",
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val = []\n",
    "\n",
    "for i in validation_gameboards:\n",
    "    val.append(np.reshape(i, (100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Loss: 0.5359411835670471, \tError: 44.53125%\n",
      "10000, Loss: 0.22292537987232208, \tError: 37.5%\n",
      "20000, Loss: 0.22419026494026184, \tError: 32.8125%\n",
      "30000, Loss: 0.24015215039253235, \tError: 42.96875%\n",
      "40000, Loss: 0.2235030233860016, \tError: 38.28125%\n",
      "50000, Loss: 0.2380937784910202, \tError: 41.40625%\n",
      "60000, Loss: 0.2364024966955185, \tError: 41.40625%\n",
      "70000, Loss: 0.2376031130552292, \tError: 42.96875%\n",
      "80000, Loss: 0.2308439016342163, \tError: 35.9375%\n",
      "90000, Loss: 0.22318801283836365, \tError: 32.8125%\n",
      "100000, Loss: 0.22272849082946777, \tError: 39.0625%\n",
      "Calculating val error\n",
      "Got 2107 val batch errors, mean: 0.40807056427001953\n",
      "Validation error after 0 Epochs: 0.40807056427001953\n",
      "Validation Errors:  [0.40807056]\n",
      "0, Loss: 0.22316737473011017, \tError: 33.59375%\n",
      "10000, Loss: 0.2216968536376953, \tError: 35.9375%\n",
      "20000, Loss: 0.23493176698684692, \tError: 38.28125%\n",
      "30000, Loss: 0.22115972638130188, \tError: 35.15625%\n",
      "40000, Loss: 0.23766973614692688, \tError: 39.84375%\n",
      "50000, Loss: 0.23260869085788727, \tError: 42.1875%\n",
      "60000, Loss: 0.23095136880874634, \tError: 39.0625%\n",
      "70000, Loss: 0.22290249168872833, \tError: 34.375%\n",
      "80000, Loss: 0.22674289345741272, \tError: 37.5%\n",
      "90000, Loss: 0.2430642545223236, \tError: 43.75%\n",
      "100000, Loss: 0.2289017140865326, \tError: 38.28125%\n",
      "Calculating val error\n",
      "Got 2107 val batch errors, mean: 0.4073660671710968\n",
      "Validation error after 1 Epochs: 0.4073660671710968\n",
      "Validation Errors:  [0.40807056, 0.40736607]\n",
      "0, Loss: 0.23654510080814362, \tError: 39.0625%\n",
      "10000, Loss: 0.23923730850219727, \tError: 39.84375%\n",
      "20000, Loss: 0.2300594449043274, \tError: 39.0625%\n",
      "30000, Loss: 0.2231835126876831, \tError: 34.375%\n",
      "40000, Loss: 0.214732825756073, \tError: 32.03125%\n",
      "50000, Loss: 0.23084980249404907, \tError: 42.1875%\n",
      "60000, Loss: 0.23878538608551025, \tError: 49.21875%\n",
      "70000, Loss: 0.23272386193275452, \tError: 36.71875%\n",
      "80000, Loss: 0.2266232967376709, \tError: 39.0625%\n",
      "90000, Loss: 0.23945197463035583, \tError: 42.96875%\n",
      "100000, Loss: 0.22679927945137024, \tError: 33.59375%\n",
      "Calculating val error\n",
      "Got 2107 val batch errors, mean: 0.40552327036857605\n",
      "Validation error after 2 Epochs: 0.40552327036857605\n",
      "Validation Errors:  [0.40807056, 0.40736607, 0.40552327]\n",
      "0, Loss: 0.23557470738887787, \tError: 44.53125%\n",
      "10000, Loss: 0.23175814747810364, \tError: 40.625%\n",
      "20000, Loss: 0.25278908014297485, \tError: 50.0%\n",
      "30000, Loss: 0.23028907179832458, \tError: 37.5%\n",
      "40000, Loss: 0.23404709994792938, \tError: 43.75%\n",
      "50000, Loss: 0.22952550649642944, \tError: 39.84375%\n",
      "60000, Loss: 0.2344384640455246, \tError: 37.5%\n",
      "70000, Loss: 0.22873245179653168, \tError: 38.28125%\n",
      "80000, Loss: 0.23219117522239685, \tError: 38.28125%\n",
      "90000, Loss: 0.2286141812801361, \tError: 36.71875%\n",
      "100000, Loss: 0.22402682900428772, \tError: 39.0625%\n",
      "Calculating val error\n",
      "Got 2107 val batch errors, mean: 0.40550100803375244\n",
      "Validation error after 3 Epochs: 0.40550100803375244\n",
      "Validation Errors:  [0.40807056, 0.40736607, 0.40552327, 0.40550101]\n",
      "0, Loss: 0.2347128987312317, \tError: 40.625%\n",
      "10000, Loss: 0.23548045754432678, \tError: 39.0625%\n",
      "20000, Loss: 0.24274781346321106, \tError: 43.75%\n",
      "30000, Loss: 0.2496977001428604, \tError: 45.3125%\n",
      "40000, Loss: 0.22236645221710205, \tError: 33.59375%\n",
      "50000, Loss: 0.22838051617145538, \tError: 36.71875%\n",
      "60000, Loss: 0.2389686107635498, \tError: 42.96875%\n",
      "70000, Loss: 0.2431417554616928, \tError: 43.75%\n",
      "80000, Loss: 0.23747530579566956, \tError: 42.1875%\n",
      "90000, Loss: 0.22540098428726196, \tError: 35.9375%\n",
      "100000, Loss: 0.20799113810062408, \tError: 27.34375%\n",
      "Calculating val error\n",
      "Got 2107 val batch errors, mean: 0.4091161787509918\n",
      "Validation error after 4 Epochs: 0.4091161787509918\n",
      "Validation Errors:  [0.40807056, 0.40736607, 0.40552327, 0.40550101, 0.40911618]\n",
      "0, Loss: 0.23937754333019257, \tError: 42.1875%\n",
      "10000, Loss: 0.23964235186576843, \tError: 43.75%\n",
      "20000, Loss: 0.22148606181144714, \tError: 33.59375%\n",
      "30000, Loss: 0.23287555575370789, \tError: 39.84375%\n",
      "40000, Loss: 0.24410268664360046, \tError: 46.875%\n",
      "50000, Loss: 0.2385324239730835, \tError: 42.1875%\n",
      "60000, Loss: 0.23805472254753113, \tError: 43.75%\n",
      "70000, Loss: 0.22699955105781555, \tError: 43.75%\n",
      "80000, Loss: 0.22280925512313843, \tError: 36.71875%\n",
      "90000, Loss: 0.22675177454948425, \tError: 39.84375%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-b239c68ba3d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0merrors_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mgameboards\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msecond_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlbl\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfirst_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msecond_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating val error\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\Anaconda3\\envs\\tf\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \"\"\"\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "errors_val = [[],[]]\n",
    "errors_train = [[],[]]\n",
    "\n",
    "for epoch in range(20):\n",
    "    #randomise the data\n",
    "    gb, lbl  = get_randomised_batches(train_gameboards, train_labels)\n",
    "    \n",
    "    for i in range(N_BATCHES):\n",
    "        first_index = i*BATCH_SIZE\n",
    "        second_index = (i*BATCH_SIZE) + BATCH_SIZE\n",
    "        #batch = gb[first_index:second_index]\n",
    "        #batchLabels = lbl[first_index:second_index]      \n",
    "        \n",
    "        #print(np.asarray(batch).shape)\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            Error, Loss = sess.run([error, loss], feed_dict={gameboards:gb[first_index:second_index], labels:lbl[first_index:second_index], keep_prob:1.0})\n",
    "            print(\"{}, Loss: {}, \\tError: {}%\".format(i, Loss, Error*100))\n",
    "            errors_train[0].append(epoch)\n",
    "            errors_train[1].append(Error)\n",
    "\n",
    "        sess.run(train, feed_dict={gameboards:gb[first_index:second_index], labels:lbl[first_index:second_index], keep_prob:0.5})\n",
    "            \n",
    "    print(\"Calculating val error\")\n",
    "    val_batch_errors = []\n",
    "    for i in range(val_batches):\n",
    "        first = i*BATCH_SIZE\n",
    "        second = first + BATCH_SIZE\n",
    "        \n",
    "        val_batch_errors.append(sess.run(error, feed_dict={gameboards:val[first:second], labels:validation_labels[first:second], keep_prob:1.0}))\n",
    "    val_mean = np.mean(val_batch_errors)\n",
    "    print(\"Got {} val batch errors, mean: {}\".format(len(val_batch_errors), val_mean))\n",
    "    print(\"Validation error after {} Epochs: {}\".format(epoch, val_mean))  \n",
    "    errors_val[0].append(epoch)\n",
    "    errors_val[1].append(val_mean)\n",
    "    print(\"Validation Errors: \", errors_val[1])\n",
    "    saver.save(sess, \"nn_model\\\\\", global_step=epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nums = np.arange(10)\n",
    "#print(nums)\n",
    "\n",
    "#plt.plot(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test = []\n",
    "\n",
    "#for i in test_gameboards:\n",
    "    #test.append(np.reshape(i, (100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Error = sess.run(error, feed_dict={gameboards:test, labels:test_labels, keep_prob:1.0})\n",
    "#print(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"for i in range(100):\n",
    "    r = sess.run(predictions, feed_dict={gameboards:[val[i]], keep_prob:1.0})\n",
    "    print(r, validation_labels[i])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

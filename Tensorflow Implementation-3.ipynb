{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import dbGeneration as db\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned data points in 81 batches\n"
     ]
    }
   ],
   "source": [
    "tensorInputs, raw_labels = db.get_tensorinputs_and_labels(folderName = \"3per\")\n",
    "tensorInputs = np.asarray(tensorInputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338448 training samples\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "\n",
    "for i in tensorInputs:\n",
    "    n += len(i)\n",
    "    \n",
    "print(n, \"training samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "print(len(raw_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81]\n",
      "338448\n",
      "338448\n",
      "[[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0. -1.  0.  0.  1.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0. -1. -1. -1.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  1. -1. -1.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  1.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(tensorInputs.shape))\n",
    "\n",
    "tensorInputs2 = []\n",
    "raw_labels2 = []\n",
    "\n",
    "for i in tensorInputs:\n",
    "    for j in i:\n",
    "        tensorInputs2.append(j)\n",
    "\n",
    "for i in raw_labels:\n",
    "    for j in i:\n",
    "        raw_labels2.append(j)\n",
    "\n",
    "print(len(tensorInputs2))\n",
    "print(len(raw_labels2))\n",
    "\n",
    "print(tensorInputs2[0])\n",
    "print(raw_labels2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_labels = raw_labels2\n",
    "tensorInputs = tensorInputs2\n",
    "del(raw_labels2)\n",
    "del(tensorInputs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(raw_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert labels to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_labels = []\n",
    "for i in raw_labels:\n",
    "    if i == -1:\n",
    "        pre_labels.append([1,0])\n",
    "    else:\n",
    "        pre_labels.append([0,1])\n",
    "\n",
    "pre_labels = np.asarray(pre_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(338448, 2)\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ..., \n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(pre_labels.shape)\n",
    "print(pre_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338448\n"
     ]
    }
   ],
   "source": [
    "print(len(tensorInputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "N_SAMPLES = len(tensorInputs)\n",
    "N_TRAIN = 320000\n",
    "N_VALIDATION = int((N_SAMPLES - N_TRAIN)/2)\n",
    "N_BATCHES = int(N_TRAIN/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    }
   ],
   "source": [
    "print(N_BATCHES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle data to avoid grouping among games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_randomised_batches(training_data, training_labels):\n",
    "    pairs = []\n",
    "    for i in range(len(training_data)):\n",
    "        pairs.append([training_data[i], training_labels[i]])\n",
    "        \n",
    "    random.shuffle(pairs)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in pairs:\n",
    "        x.append(np.reshape(i[0], (100)))\n",
    "        y.append(i[1])\n",
    "        \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gameboards = tensorInputs[:N_TRAIN]\n",
    "validation_gameboards = tensorInputs[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_gameboards = tensorInputs[N_TRAIN+N_VALIDATION:]\n",
    "\n",
    "train_labels = pre_labels[:N_TRAIN]\n",
    "validation_labels = pre_labels[N_TRAIN:N_TRAIN+N_VALIDATION]\n",
    "test_labels = pre_labels[N_TRAIN+N_VALIDATION:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320000\n",
      "9224\n",
      "9224\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gameboards))\n",
    "print(len(validation_gameboards))\n",
    "print(len(test_gameboards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      " [ 2.  0.  0.  0.  0.  0.  0.  0.  0.  2.]\n",
      " [ 2.  0.  0.  1. -1. -1.  0.  0.  0.  2.]\n",
      " [ 2. -1.  1.  1.  1.  1. -1.  0. -1.  2.]\n",
      " [ 2.  1.  1.  1. -1.  1.  1. -1.  0.  2.]\n",
      " [ 2. -1.  1. -1.  1.  1. -1. -1.  0.  2.]\n",
      " [ 2. -1. -1.  1. -1.  1. -1. -1.  0.  2.]\n",
      " [ 2.  0.  0.  1.  1. -1.  1.  0.  0.  2.]\n",
      " [ 2.  0.  0.  1.  1.  1.  1.  1.  0.  2.]\n",
      " [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]] [1 0]\n"
     ]
    }
   ],
   "source": [
    "print(test_gameboards[0], test_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gameboards = tf.placeholder(tf.float32, (None, 100), name=\"gameBoards\")\n",
    "\n",
    "gameboards2d = tf.reshape(gameboards, (-1, 10, 10, 1), name=\"gameBoards2d\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First Convulutional layer, small 2x2 filter\n",
    "conv1 = tf.layers.conv2d(gameboards2d, 64, 2, padding=\"same\", name=\"Conv1\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, 2, 2, name=\"Pool1\")\n",
    "conv2 = tf.layers.conv2d(pool1, 128, 3, padding=\"same\", name=\"Conv2\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, 2, 2, name=\"Pool2\")\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, 128, 4, padding=\"same\", name=\"Conv3\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(conv3, 2, 2, name=\"Pool3\")\n",
    "\n",
    "# Reshape the 2D tensor back to 1D to be fed into \"Dense\"\n",
    "# Flatten out the pooling - GET THIS NUMBER FROM POOLx.SHAPE\n",
    "pool2_flat = tf.reshape(pool3, (-1, int(1*1*128)), name=\"Pool2_Flat\")\n",
    "\n",
    "\n",
    "# The dropout allows us to train a subset of the neurons at any given iteration.  \n",
    "keep_prob = tf.placeholder(tf.float32, name=\"Keep_Probability\")\n",
    "\n",
    "\n",
    "# A dense layer with dropout\n",
    "# DENSE - a fully connected linear transofmration of every dimension of the data\n",
    "dense = tf.layers.dense(pool2_flat, int(128), activation=tf.nn.relu, name=\"Dense\")\n",
    "\n",
    "# DROPOUT - if set to 0.5, rendomly select 50% of the neurons to ignore (different with each computation)\n",
    "dropout = tf.nn.dropout(dense, keep_prob, name=\"Dropout\")\n",
    "\n",
    "dense2 = tf.layers.dense(dropout, int(128), activation=tf.nn.relu, name=\"Dense2\")\n",
    "dropout2 = tf.nn.dropout(dense2, keep_prob, name=\"Dropout2\")\n",
    "\n",
    "\"\"\"dense3 = tf.layers.dense(dropout, int(128), activation=tf.nn.relu, name=\"Dense3\")\n",
    "dropout3 = tf.nn.dropout(dense3, keep_prob, name=\"Dropout3\")\"\"\"\n",
    "\n",
    "# A dense layer to classify the final values. Only 2 neurons. \n",
    "predictions = tf.layers.dense(dropout2, 2, activation=None, name=\"Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 1, 64)\n",
      "4\n",
      "2\n",
      "2\n",
      "1\n",
      "64\n",
      "256\n",
      "(64,)\n",
      "1\n",
      "64\n",
      "64\n",
      "(3, 3, 64, 128)\n",
      "4\n",
      "3\n",
      "3\n",
      "64\n",
      "128\n",
      "73728\n",
      "(128,)\n",
      "1\n",
      "128\n",
      "128\n",
      "(4, 4, 128, 128)\n",
      "4\n",
      "4\n",
      "4\n",
      "128\n",
      "128\n",
      "262144\n",
      "(128,)\n",
      "1\n",
      "128\n",
      "128\n",
      "(128, 128)\n",
      "2\n",
      "128\n",
      "128\n",
      "16384\n",
      "(128,)\n",
      "1\n",
      "128\n",
      "128\n",
      "(128, 128)\n",
      "2\n",
      "128\n",
      "128\n",
      "16384\n",
      "(128,)\n",
      "1\n",
      "128\n",
      "128\n",
      "(128, 2)\n",
      "2\n",
      "128\n",
      "2\n",
      "256\n",
      "(2,)\n",
      "1\n",
      "2\n",
      "2\n",
      "369730\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    print(shape)\n",
    "    print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "    print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(1), Dimension(1), Dimension(128)])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# None, as in, this is not yet defined, there could be any number of them input. \n",
    "# 2, as in, there are two elements in the one-hot vector\n",
    "\n",
    "labels = tf.placeholder(tf.int32, [None, 2], name=\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This loss is the elementwise loss\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits)\n",
    "\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=predictions))\n",
    "\n",
    "\"\"\"with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\"\"\"\n",
    "\n",
    "with tf.name_scope(\"Optimizer\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.001, name=\"Adam\").minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Error\"):\n",
    "    error = tf.reduce_mean(\n",
    "        tf.cast(tf.not_equal(tf.argmax(labels, 1), tf.argmax(predictions, 1)), tf.float32), name=\"Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define an error rate to evaluate model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Error_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Error\", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n"
     ]
    }
   ],
   "source": [
    "number_of_batches = int(N_TRAIN / BATCH_SIZE)\n",
    "print(number_of_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, Loss: 0.6943117380142212, \tError: 56.25%\n",
      "100, Loss: 0.651033341884613, \tError: 39.0625%\n",
      "200, Loss: 0.6728786826133728, \tError: 41.40625%\n",
      "300, Loss: 0.658026933670044, \tError: 42.578125%\n",
      "400, Loss: 0.6569036841392517, \tError: 42.1875%\n",
      "500, Loss: 0.6429314613342285, \tError: 34.765625%\n",
      "600, Loss: 0.6106640100479126, \tError: 35.546875%\n",
      "700, Loss: 0.6496871709823608, \tError: 40.625%\n",
      "800, Loss: 0.6664119958877563, \tError: 36.71875%\n",
      "900, Loss: 0.6470652222633362, \tError: 36.71875%\n",
      "1000, Loss: 0.6233158111572266, \tError: 33.59375%\n",
      "1100, Loss: 0.6245087385177612, \tError: 36.328125%\n",
      "1200, Loss: 0.6418462991714478, \tError: 37.5%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    #randomise the data\n",
    "    gb, lbl  = get_randomised_batches(train_gameboards, train_labels)\n",
    "    \n",
    "    for i in range(N_BATCHES):\n",
    "        first_index = i*BATCH_SIZE\n",
    "        second_index = (i*BATCH_SIZE) + BATCH_SIZE\n",
    "        batch = gb[first_index:second_index]\n",
    "        batchLabels = lbl[first_index:second_index]\n",
    "\n",
    "        #print(np.asarray(batch).shape)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            Error, Loss = sess.run([error, loss], feed_dict={gameboards:batch, labels:batchLabels, keep_prob:1.0})\n",
    "            print(\"{}, Loss: {}, \\tError: {}%\".format(i, Loss, Error*100))\n",
    "        sess.run(train, feed_dict={gameboards:batch, labels:batchLabels, keep_prob:0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val = []\n",
    "\n",
    "for i in validation_gameboards:\n",
    "    val.append(np.reshape(i, (100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#test = []\n",
    "\n",
    "#for i in test_gameboards:\n",
    "    #test.append(np.reshape(i, (100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.385191\n"
     ]
    }
   ],
   "source": [
    "Error = sess.run(error, feed_dict={gameboards:val, labels:validation_labels, keep_prob:1.0})\n",
    "print(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Error = sess.run(error, feed_dict={gameboards:test, labels:test_labels, keep_prob:1.0})\n",
    "#print(Error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nn_model\\\\'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess, \"nn_model\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20382451 -0.09565792]] [0 1]\n",
      "[[ 0.18464547 -0.08911093]] [0 1]\n",
      "[[ 0.26652789 -0.12469832]] [0 1]\n",
      "[[ 0.3028461  -0.14244349]] [1 0]\n",
      "[[ 0.17877287 -0.07484733]] [1 0]\n",
      "[[ 0.82947767 -0.48222473]] [1 0]\n",
      "[[ 0.05582605 -0.01011826]] [0 1]\n",
      "[[-0.00897887  0.0495826 ]] [0 1]\n",
      "[[-0.04630198  0.09065548]] [0 1]\n",
      "[[ 0.23430805 -0.10631594]] [0 1]\n",
      "[[ 0.00642218  0.05507131]] [0 1]\n",
      "[[ 0.01595702  0.0363302 ]] [0 1]\n",
      "[[-0.07293038  0.11721419]] [0 1]\n",
      "[[-0.32008162  0.40287516]] [0 1]\n",
      "[[-0.11103632  0.17234212]] [0 1]\n",
      "[[ 0.06609468 -0.01888115]] [1 0]\n",
      "[[-0.01011379  0.04852433]] [1 0]\n",
      "[[ 0.57031024 -0.2735377 ]] [1 0]\n",
      "[[ 0.19957274 -0.0944072 ]] [0 1]\n",
      "[[ 0.18103392 -0.08464561]] [0 1]\n",
      "[[-0.54026276  0.69360888]] [0 1]\n",
      "[[ 0.17231245 -0.0796057 ]] [1 0]\n",
      "[[ 0.10663161 -0.0580479 ]] [0 1]\n",
      "[[ 0.04098496 -0.00874101]] [0 1]\n",
      "[[ 0.15553157 -0.07840641]] [0 1]\n",
      "[[ 0.14020337 -0.06650194]] [1 0]\n",
      "[[ 0.18814886 -0.08472127]] [1 0]\n",
      "[[ 0.18670744 -0.08604512]] [1 0]\n",
      "[[ 0.21629985 -0.09472647]] [1 0]\n",
      "[[ 0.23282041 -0.10197512]] [1 0]\n",
      "[[ 2.18211126 -1.4540031 ]] [1 0]\n",
      "[[ 0.30337697 -0.14353922]] [1 0]\n",
      "[[ 0.4142305  -0.20031142]] [1 0]\n",
      "[[ 0.69194245 -0.37061864]] [1 0]\n",
      "[[ 0.05012164  0.00409496]] [1 0]\n",
      "[[ 0.07653999 -0.01961907]] [1 0]\n",
      "[[ 0.06664352 -0.00467861]] [1 0]\n",
      "[[ 0.19252542 -0.08947574]] [0 1]\n",
      "[[ 0.20923349 -0.09558588]] [0 1]\n",
      "[[ 0.23090991 -0.10458853]] [0 1]\n",
      "[[ 0.215064   -0.09654355]] [1 0]\n",
      "[[ 0.23788476 -0.10552351]] [1 0]\n",
      "[[ 0.01426569  0.04448337]] [1 0]\n",
      "[[ 0.20639345 -0.09593791]] [1 0]\n",
      "[[ 0.145777   -0.07429162]] [1 0]\n",
      "[[-0.07107465  0.11632691]] [1 0]\n",
      "[[-0.12298414  0.18938263]] [1 0]\n",
      "[[ 0.51895326 -0.27747926]] [1 0]\n",
      "[[ 0.93535364 -0.57689255]] [1 0]\n",
      "[[ 0.20955962 -0.09395608]] [0 1]\n",
      "[[ 0.03484719  0.00148235]] [0 1]\n",
      "[[-0.04594207  0.08373578]] [0 1]\n",
      "[[ 0.17552973 -0.08590031]] [1 0]\n",
      "[[ 0.19894511 -0.09017859]] [1 0]\n",
      "[[ 0.22822607 -0.10205745]] [1 0]\n",
      "[[ 0.22552118 -0.10226619]] [1 0]\n",
      "[[ 0.44582665 -0.23032832]] [1 0]\n",
      "[[ 0.20189807 -0.09377041]] [0 1]\n",
      "[[ 0.21257137 -0.09265901]] [0 1]\n",
      "[[-0.64496154  0.77775151]] [0 1]\n",
      "[[ 0.15244719 -0.07607788]] [1 0]\n",
      "[[ 0.18976001 -0.09261541]] [1 0]\n",
      "[[-0.08941001  0.14118324]] [1 0]\n",
      "[[ 0.16528797 -0.07589674]] [1 0]\n",
      "[[ 0.24044356 -0.10925348]] [1 0]\n",
      "[[ 0.23398791 -0.10636501]] [1 0]\n",
      "[[ 0.20296766 -0.09594559]] [0 1]\n",
      "[[ 0.16671801 -0.08594565]] [0 1]\n",
      "[[ 0.1755119  -0.07892374]] [0 1]\n",
      "[[ 0.18505304 -0.0862989 ]] [0 1]\n",
      "[[ 0.16952926 -0.07907928]] [0 1]\n",
      "[[ 0.40408182 -0.19481586]] [0 1]\n",
      "[[ 0.16037935 -0.07318883]] [1 0]\n",
      "[[ 0.20129558 -0.09549244]] [1 0]\n",
      "[[ 0.75393665 -0.42562711]] [1 0]\n",
      "[[ 0.15890461 -0.06949357]] [0 1]\n",
      "[[ 0.16995181 -0.08236695]] [0 1]\n",
      "[[ 0.03456112  0.02042155]] [0 1]\n",
      "[[ 0.15890461 -0.06949357]] [1 0]\n",
      "[[-0.03391526  0.08092456]] [1 0]\n",
      "[[-0.51592857  0.64198953]] [1 0]\n",
      "[[ 0.14020337 -0.06650194]] [1 0]\n",
      "[[ 0.21494213 -0.09845273]] [1 0]\n",
      "[[ 0.37035343 -0.17446171]] [1 0]\n",
      "[[ 0.18262012 -0.088427  ]] [1 0]\n",
      "[[-0.15958056  0.23840974]] [1 0]\n",
      "[[-0.39820522  0.52529198]] [1 0]\n",
      "[[ 0.14205764 -0.07079585]] [1 0]\n",
      "[[-0.15430735  0.21372376]] [1 0]\n",
      "[[-0.08268693  0.1317794 ]] [1 0]\n",
      "[[ 0.20944436 -0.09568441]] [0 1]\n",
      "[[-0.00613369  0.04196985]] [0 1]\n",
      "[[-0.34948891  0.44232756]] [0 1]\n",
      "[[ 0.17606501 -0.0808713 ]] [0 1]\n",
      "[[ 0.21820575 -0.09887068]] [0 1]\n",
      "[[-1.14143717  1.3757484 ]] [0 1]\n",
      "[[ 0.14020337 -0.06650194]] [1 0]\n",
      "[[ 0.0769482  -0.00917333]] [1 0]\n",
      "[[ 0.1531269  -0.07270671]] [1 0]\n",
      "[[ 0.14156681 -0.06316273]] [0 1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    r = sess.run(predictions, feed_dict={gameboards:[val[i]], keep_prob:1.0})\n",
    "    print(r, validation_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14156681 -0.06316273]]\n"
     ]
    }
   ],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
